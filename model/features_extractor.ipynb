{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Colab section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_nwFe_Q_Wsd",
        "outputId": "f90a7ca1-f68b-445b-b2c6-008fa82202ad"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "imQ1IVo3owU1"
      },
      "outputs": [],
      "source": [
        "# !mkdir /content/models\n",
        "# base_folder = \"/content/drive/MyDrive/MRI\"\n",
        "# !cp -a '/content/drive/MyDrive/MRI/dataset' '.'\n",
        "# !cp -a '/content/drive/MyDrive/MRI/file_list.csv' '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naecXrY0_huQ",
        "outputId": "098a1ee0-2af6-4f1b-cd9b-1add1243adad"
      },
      "outputs": [],
      "source": [
        "# !pip install torchio segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i6vzAEG9wIl"
      },
      "source": [
        "Training the feature extraction model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i5l_BBBtq3eH"
      },
      "outputs": [],
      "source": [
        "feature_extract=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y6wcns0v9wI2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LateFusion3DCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(LateFusion3DCNN, self).__init__()\n",
        "        # Define separate pathways for each modality with added depth\n",
        "        self.pathway_mri = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, structuctuctide=2),\n",
        "            nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.pathway_dose = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.pathway_struct = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Adjusted feature extractor to return 128-dimensional vector\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Adjusted linear layer to output 128 features\n",
        "            nn.Linear(32 * 3 * 16 * 16 * 16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        # Final classification layer, now optional based on feature_extract flag\n",
        "        self.classifier = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x_mri, x_dose, x_struct, feature_extract=False):\n",
        "        # Process each modality through its pathway\n",
        "        x_mri = self.pathway_mri(x_mri)\n",
        "        x_dose = self.pathway_dose(x_dose)\n",
        "        x_struct = self.pathway_struct(x_struct)\n",
        "\n",
        "        # Flatten outputs for concatenation\n",
        "        x_mri = torch.flatten(x_mri, start_dim=1)\n",
        "        x_dose = torch.flatten(x_dose, start_dim=1)\n",
        "        x_struct = torch.flatten(x_struct, start_dim=1)\n",
        "\n",
        "        # Concatenate the flattened outputs\n",
        "        x_fused = torch.cat((x_mri, x_dose, x_struct), dim=1)\n",
        "\n",
        "        # Pass concatenated features through the adjusted feature extractor\n",
        "        features = self.feature_extractor(x_fused)\n",
        "\n",
        "        # Return 128-dimensional feature vector if feature_extract is True\n",
        "        if feature_extract:\n",
        "            return features\n",
        "\n",
        "        # Otherwise, classify\n",
        "        out = self.classifier(features)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MidFusion3DCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(MidFusion3DCNN, self).__init__()\n",
        "        # Initial separate pathways for MRI, dose, and structural modalities\n",
        "        self.pathway_mri = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.pathway_dose = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.pathway_struct = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Fusion layer to combine features from all modalities\n",
        "        self.fusion_conv = nn.Conv3d(in_channels=48, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.fusion_bn = nn.BatchNorm3d(64)\n",
        "        self.fusion_pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Feature extractor part (Adjusted based on the actual output size before flattening)\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Placeholder for adjusted size; calculate the correct value based on input dimensions\n",
        "            nn.Linear(64 * 16 * 16 * 16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        # Final classification layer\n",
        "        self.classifier = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x_mri, x_dose, x_struct, feature_extract=feature_extract):\n",
        "        # Process each modality through its respective pathway\n",
        "        x_mri = self.pathway_mri(x_mri)\n",
        "        x_dose = self.pathway_dose(x_dose)\n",
        "        x_struct = self.pathway_struct(x_struct)\n",
        "\n",
        "        # Fusion of features from all pathways\n",
        "        x_fused = torch.cat((x_mri, x_dose, x_struct), dim=1)\n",
        "        x_fused = F.relu(self.fusion_bn(self.fusion_conv(x_fused)))\n",
        "        x_fused = self.fusion_pool(x_fused)\n",
        "\n",
        "        # Extract features\n",
        "        features = self.feature_extractor(x_fused)\n",
        "\n",
        "        # If feature extraction mode, return features directly\n",
        "        if feature_extract:\n",
        "            return features\n",
        "\n",
        "        # Otherwise, classify\n",
        "        out = self.classifier(features)\n",
        "        return out\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EarlyFusion3DCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        # Initialize 3D convolution layer\n",
        "        self.conv1 = nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "        # Initialize batch normalization for 3D data\n",
        "        self.bn1 = nn.BatchNorm3d(16)\n",
        "        # Initialize 3D max pooling layer\n",
        "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Sequential container for feature extraction layers\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv3d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(2),\n",
        "            nn.Flatten(),  # Flatten the output for the linear layer\n",
        "            nn.Linear(32 * 16 * 16 * 16, 128),  # Adjust the input features accordingly\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)  # Dropout for regularization\n",
        "        )\n",
        "\n",
        "        # Classifier with a linear layer\n",
        "        self.classifier = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x_mri, x_dose, x_struct, feature_extract=feature_extract):\n",
        "        # Concatenate the input tensors along the channel dimension\n",
        "        x = torch.cat((x_mri, x_dose, x_struct), dim=1)\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        features = self.feature_extractor(x)\n",
        "\n",
        "        # Optionally return extracted features before classification\n",
        "        if feature_extract:\n",
        "            return features\n",
        "\n",
        "        # Pass features through the classifier\n",
        "        out = self.classifier(features)\n",
        "        return out\n",
        "\n",
        "# Setup the device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A3PgR-199wI2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchio as tio\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "\n",
        "def load_npy_file(file_path, normalize=True, new_min=0, new_max=1):\n",
        "    \"\"\"\n",
        "    Load a .npy file, optionally apply min-max normalization, and return it.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        image_data = np.load(file_path).astype(np.float32)  # Ensure data is in float32\n",
        "        if normalize:\n",
        "            # Apply min-max normalization\n",
        "            min_val = image_data.min()\n",
        "            max_val = image_data.max()\n",
        "            if max_val - min_val > 0:\n",
        "                image_data = (image_data - min_val) / (max_val - min_val) * (new_max - new_min) + new_min\n",
        "            else:\n",
        "                print(f\"Warning: Not normalizing {file_path} due to division by zero.\")\n",
        "        return image_data\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def data_loading_and_augmentation(folder_path='dataset', csv_file_path='file_list.csv'):\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    subjects_list = []\n",
        "\n",
        "    grouped_df = df.groupby(['pid', 'course', 'lesion'])\n",
        "\n",
        "    for _, group in grouped_df:\n",
        "        row = group[['pid', 'course', 'lesion']].iloc[0]\n",
        "        lesion = f\"{row['pid']}_{row['course']}_{row['lesion'].split('.')[0]}\"\n",
        "\n",
        "        group.set_index('modality', inplace=True)\n",
        "        subject_dict = {'label': group['recurrence'].iloc[0], 'mri': None, 'dose': None, 'struct': None, 'file_names':[], 'lesion':lesion}\n",
        "\n",
        "        for modality in ['mri', 'dose', 'struct']:\n",
        "            if modality in group.index:\n",
        "                file_name = group.loc[modality, 'filename']\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "                image_data = load_npy_file(file_path)\n",
        "                # Add a channels dimension\n",
        "                image_data = image_data[np.newaxis, ...]  # Convert shape (64, 64, 64) to (1, 64, 64, 64)\n",
        "                # Wrap the numpy array with tio.ScalarImage\n",
        "                subject_dict[modality] = tio.ScalarImage(tensor=torch.from_numpy(image_data))\n",
        "                subject_dict['file_names'].append(file_name)\n",
        "\n",
        "        subject = tio.Subject(\n",
        "            mri=subject_dict['mri'] if subject_dict['mri'] is not None else tio.ScalarImage(tensor=torch.zeros(1, 1, 64, 64, 64, dtype=torch.float32)),\n",
        "            dose=subject_dict['dose'] if subject_dict['dose'] is not None else tio.ScalarImage(tensor=torch.zeros(1, 1, 64, 64, 64, dtype=torch.float32)),\n",
        "            struct=subject_dict['struct'] if subject_dict['struct'] is not None else tio.ScalarImage(tensor=torch.zeros(1, 1, 64, 64, 64, dtype=torch.float32)),\n",
        "            label=subject_dict['label'],\n",
        "            lesion=subject_dict['lesion'],\n",
        "            file_names=subject_dict['file_names']\n",
        "        )\n",
        "\n",
        "        subjects_list.append(subject)\n",
        "\n",
        "    return subjects_list\n",
        "\n",
        "# Define augmentation transformations\n",
        "augmentation_transforms = tio.Compose([\n",
        "    tio.OneOf({\n",
        "        tio.RandomAffine(scales=0, degrees=180): 1/7,\n",
        "        tio.RandomAffine(scales=0, degrees=90): 1/7,\n",
        "        tio.RandomFlip(axes=0): 1/7,\n",
        "        tio.RandomFlip(axes=1): 1/7,\n",
        "        tio.RandomAffine(degrees=0, translation=0): 1/7,\n",
        "        tio.RandomBlur(): 1/7,\n",
        "        tio.RandomNoise(): 1/7,\n",
        "    }),\n",
        "    # tio.transforms.Pad((64, 64, 64)),\n",
        "])\n",
        "\n",
        "# Data loading and augmentation\n",
        "subjects_list = data_loading_and_augmentation()\n",
        "\n",
        "# Split the data with stratification\n",
        "train_subjects, temp_subjects, train_labels, temp_labels = train_test_split(data_loading_and_augmentation(), [subject['label'] for subject in subjects_list], test_size=0.3, random_state=42, stratify=[subject['label'] for subject in subjects_list])\n",
        "val_subjects, test_subjects, val_labels, test_labels = train_test_split(temp_subjects, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "243_2_Right Motor Cortex 0\n",
            "420_1_Right Medial Frontal 0\n",
            "330_1_Right Frontal 0\n",
            "219_3_Left Medial Cerebellar 0\n",
            "152_3_Right Median Parietal 0\n",
            "152_3_Left Frontal Pole 0\n",
            "152_3_Left Superior Frontal 0\n",
            "467_1_Left Anterior Temporal 0\n",
            "243_1_Left Temporal 0\n",
            "467_1_Left Anterior Frontal 0\n",
            "338_1_Right Postcentral Gyrus 0\n",
            "152_3_Left Medial Parietal 0\n",
            "243_2_Right Superior Cerebellar 1 0\n",
            "492_1_Left Para Median 0\n",
            "243_2_Right Frontal 0\n",
            "152_3_Left Parietal 2 0\n",
            "492_1_Left Occipital 1 0\n",
            "257_5_Right Cerebellar 0\n",
            "243_3_Left Ventricle 1\n",
            "152_3_Right Anterior Frontal 2 0\n",
            "492_1_Left Superior Parietal 0\n",
            "114_1_Left Temporal 0\n",
            "338_1_Right Superior Frontal Gyrus 1\n",
            "246_1_Left Frontal 0\n",
            "152_3_Left Frontal Lateral 0\n",
            "147_2_Left Medial Occipital 0\n",
            "463_2_Left Lateral Cerebellum 0\n",
            "427_1_Left Temporal 0\n",
            "243_2_Right Occipital 0\n",
            "246_1_Cerebellar 0\n",
            "492_2_Right Temporal 0\n",
            "467_1_Left Insula 1\n",
            "467_1_Right Occipital 0\n",
            "257_3_Right Cerebellum 0\n",
            "492_1_Left Frontal Cavity 0\n",
            "243_2_Right Superior Medial Occipital 0\n",
            "427_3_Occipital Tentorial 1\n"
          ]
        }
      ],
      "source": [
        "for s in val_subjects:\n",
        "    print(s['lesion'],s['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8Go5Aa0z9wI2"
      },
      "outputs": [],
      "source": [
        "def init_weights_he(m):\n",
        "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "def evaluate_model_on_dataloader(dataloader, model, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad(), autocast(enabled=True):  # Disable gradient calculation for inference\n",
        "        for subject in dataloader:\n",
        "            # Extract data and move to the specified device\n",
        "            mri = subject['mri'][tio.DATA].to(device)\n",
        "            dose = subject['dose'][tio.DATA].to(device)\n",
        "            struct = subject['struct'][tio.DATA].to(device)\n",
        "            labels = subject['label'].to(device)\n",
        "\n",
        "            # Forward pass: Compute predicted outputs by passing inputs to the model\n",
        "            outputs = model(mri, dose, struct)\n",
        "            _, preds = torch.max(outputs, 1)  # Get the predictions\n",
        "\n",
        "            # Append batch predictions and true labels to lists\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute the F1 score between true labels and predictions\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0.0)\n",
        "    return f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchio as tio\n",
        "import numpy as np\n",
        "\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "\n",
        "    def extract_features(self, dataloader):\n",
        "        features = []\n",
        "        labels = []\n",
        "        lesions = []\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()  # Ensure the model is in evaluation mode for feature extraction\n",
        "\n",
        "        with torch.no_grad():  # No gradient needed for feature extraction\n",
        "            for subject in dataloader:\n",
        "                # Assuming 'mri', 'dose', 'struct', and 'label' are keys in your dataset\n",
        "                mri = subject['mri'][tio.DATA].to(self.device)\n",
        "                dose = subject['dose'][tio.DATA].to(self.device)\n",
        "                struct = subject['struct'][tio.DATA].to(self.device)\n",
        "                label = subject['label'].to(self.device)\n",
        "                lesion = subject['lesion']\n",
        "\n",
        "                # Extract features\n",
        "                output_features = self.model(mri, dose, struct, feature_extract=True)\n",
        "\n",
        "                # Store features and labels\n",
        "                features.append(output_features.cpu().numpy())  # Convert to numpy array\n",
        "                labels.append(label.cpu().numpy())\n",
        "                lesions.append(lesion)\n",
        "\n",
        "        # Convert lists to numpy arrays for easier handling later\n",
        "        features = np.concatenate(features, axis=0)\n",
        "        labels = np.concatenate(labels, axis=0)\n",
        "        lesions = np.concatenate(lesions, axis=0)\n",
        "        return features, labels, lesions\n",
        "\n",
        "    def extract_and_store_features(self, train_dataloader, val_dataloader, test_dataloader):\n",
        "        train_features, train_labels, train_lesions = self.extract_features(train_dataloader)\n",
        "        val_features, val_labels, val_lesions = self.extract_features(val_dataloader)\n",
        "        test_features, test_labels, test_lesions = self.extract_features(test_dataloader)\n",
        "\n",
        "        # Here you could add additional logic to store these features and labels to disk\n",
        "        # For simplicity, this function just returns them\n",
        "        return (train_features, train_labels, train_lesions), (val_features, val_labels, val_lesions), (test_features, test_labels, test_lesions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sQrYF-hYUmva"
      },
      "outputs": [],
      "source": [
        "\n",
        "#FocalLoss\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import torchio as tio\n",
        "import seaborn as sns\n",
        "from torch.optim import AdamW\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.model_selection import StratifiedKFold,KFold\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,confusion_matrix\n",
        "from segmentation_models_pytorch.losses import FocalLoss\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "def run_cross_validation(X, model_constructor, learning_rate, batch_size, iteration, n_splits, num_epochs, device):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    output = {\"fold\": [], \"train_losses\": [], \"val_losses\": [], 'best_y_true':  [],'best_y_pred': [],\n",
        "              'best_f1':  [], 'train_f1': [], 'val_f1': [], 'train_features': [], 'val_features': [],\n",
        "              'test_features': [], 'best_epoch': []}\n",
        "\n",
        "    f_train_dataset = tio.SubjectsDataset(train_subjects)\n",
        "    f_train_dataloader = DataLoader(f_train_dataset, batch_size=batch_size, shuffle=False)\n",
        "    f_val_dataset = tio.SubjectsDataset(val_subjects)\n",
        "    f_val_dataloader = DataLoader(f_val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    f_test_dataset = tio.SubjectsDataset(test_subjects)\n",
        "    f_test_dataloader = DataLoader(f_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
        "        train_X, val_X = [X[i] for i in train_idx], [X[i] for i in val_idx]\n",
        "\n",
        "        # Count the class occurrences to determine weights\n",
        "        class_counts = {0: 0, 1: 0}\n",
        "        for x in train_X:\n",
        "            class_counts[x['label']] += 1  # Access the label correctly\n",
        "\n",
        "        # Calculate weights for each class based on occurrences\n",
        "        weights_per_class = {cls: 1.0 / count for cls, count in class_counts.items()}\n",
        "\n",
        "        # Assign a weight to each sample in the training set based on its class\n",
        "        sample_weights = [weights_per_class[x['label']] for x in train_X]  # Access the label correctly\n",
        "        sample_weights = torch.tensor(sample_weights, dtype=torch.float)\n",
        "\n",
        "        # Create a WeightedRandomSampler to handle class imbalance\n",
        "        sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = tio.SubjectsDataset(train_X,transform=augmentation_transforms)  # Applies augmentation conditionally\n",
        "        val_dataset = tio.SubjectsDataset(val_X)  # No augmentation for validation dataset\n",
        "\n",
        "        # Create dataloaders, utilizing the sampler for the training set to address class imbalance\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, shuffle=False)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        model = model_constructor().to(device).float()\n",
        "        model.apply(init_weights_he)\n",
        "\n",
        "        global model_name # for later ploting\n",
        "        model_name = model.__class__.__name__\n",
        "\n",
        "        # Hyperparameters configuration\n",
        "        num_train_samples = len(train_dataloader.dataset)  # Or compute it manually from your dataset\n",
        "        num_training_steps = num_train_samples // train_dataloader.batch_size * num_epochs  # Full passes through the dataset for 20 epochs\n",
        "        num_warmup_steps = round(num_training_steps * 0.1)  # Around 10% of the training data for warmup\n",
        "\n",
        "        # Instantiate the optimizer\n",
        "        optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Get the learning rate scheduler\n",
        "        total_steps = num_training_steps\n",
        "        warmup_percentage = num_warmup_steps / total_steps\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps)\n",
        "\n",
        "        # Loss Function\n",
        "        criterion = FocalLoss('binary', gamma=2.0, alpha=0.1, reduction=\"mean\", ignore_index=-1)\n",
        "\n",
        "\n",
        "        scaler = GradScaler()\n",
        "        best_val_loss = float('inf')\n",
        "        train_losses, val_losses = [], []\n",
        "        best_f1 = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            total_train_loss = 0.0\n",
        "            for subject in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs} - Training'):\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                mri = subject['mri'][tio.DATA].to(device)\n",
        "                dose = subject['dose'][tio.DATA].to(device)\n",
        "                struct = subject['struct'][tio.DATA].to(device)\n",
        "                labels = subject['label'].to(device)\n",
        "\n",
        "                # Correct placement of labels_one_hot for FocalLoss\n",
        "                labels_one_hot = F.one_hot(labels, num_classes=2).float().to(device)\n",
        "\n",
        "                with autocast():\n",
        "                    outputs = model(mri, dose, struct,feature_extract=False)\n",
        "                    loss = criterion(outputs, labels_one_hot)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = total_train_loss / len(train_dataloader.dataset)\n",
        "            train_losses.append(avg_train_loss)\n",
        "\n",
        "            model.eval()\n",
        "            total_val_loss = 0.0\n",
        "            y_pred, y_true = [], [] # it is important to place the initialization here, to we collect only the last ones in the fold\n",
        "            with torch.no_grad(), autocast():\n",
        "                for subject in tqdm(val_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs} - Validation'):\n",
        "                    mri = subject['mri'][tio.DATA].to(device)\n",
        "                    dose = subject['dose'][tio.DATA].to(device)\n",
        "                    struct = subject['struct'][tio.DATA].to(device)\n",
        "                    labels = subject['label'].to(device)\n",
        "                    labels_one_hot = F.one_hot(labels, num_classes=2).float().to(device)  # Added for validation\n",
        "\n",
        "                    outputs = model(mri, dose, struct)  # No feature_extract=True\n",
        "                    loss = criterion(outputs, labels_one_hot)\n",
        "                    total_val_loss += loss.item()\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    y_pred.extend(preds.cpu().numpy())\n",
        "                    y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "            avg_val_loss = total_val_loss / len(val_dataloader.dataset)\n",
        "            val_losses.append(avg_val_loss)\n",
        "\n",
        "            f1,precision,recall=f1_score(y_true, y_pred,zero_division=0.0),precision_score(y_true, y_pred,zero_division=0.0),recall_score(y_true, y_pred,zero_division=0.0)\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}: Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "            print(f\"Validation - F1/Precision/Recall: {f1:.4f}/{precision:.4f}/{recall:.4f}\")\n",
        "            print(f\"Validation - y_true: {y_true}\\nValidation - y_pred: {y_pred}\")\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_epoch = epoch\n",
        "                best_y_pred = y_pred\n",
        "                best_y_true = y_true\n",
        "                print(f\"New best F1 score: {best_f1:.4f}\")\n",
        "                fe = FeatureExtractor(model, device)\n",
        "                train_features,val_features,test_features = fe.extract_and_store_features(f_train_dataloader, f_val_dataloader, f_test_dataloader)\n",
        "                train_f1 = evaluate_model_on_dataloader(f_train_dataloader,model,device)\n",
        "                val_f1 = evaluate_model_on_dataloader(f_val_dataloader,model,device)\n",
        "            if avg_val_loss < best_val_loss:\n",
        "                best_val_loss = avg_val_loss\n",
        "                print(f\"New best val loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "        # Accumulate the stats for this iteration and fold\n",
        "        output['fold'].append(fold)\n",
        "        output['best_y_true'].append(best_y_true)\n",
        "        output['best_y_pred'].append(best_y_pred)\n",
        "        output['train_losses'].append(train_losses)\n",
        "        output['val_losses'].append(val_losses)\n",
        "        output['best_f1'].append(best_f1)\n",
        "        output['train_f1'].append(train_f1)\n",
        "        output['val_f1'].append(val_f1)\n",
        "        output['train_features'].append(train_features)\n",
        "        output['val_features'].append(val_features)\n",
        "        output['test_features'].append(test_features)\n",
        "        output['best_epoch'].append(best_epoch)\n",
        "\n",
        "        # Free up memory (if on GPU)\n",
        "        del model, optimizer, scheduler, train_dataloader, val_dataloader\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CeHmHhz4cRFO"
      },
      "outputs": [],
      "source": [
        "#CrossEntropy\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import torchio as tio\n",
        "import seaborn as sns\n",
        "from torch.optim import AdamW\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.model_selection import StratifiedKFold,KFold\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,confusion_matrix\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "def run_cross_validation(X, model_constructor, learning_rate, batch_size, iteration, n_splits, num_epochs, device):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    output = {\"fold\": [], \"train_losses\": [], \"val_losses\": [], 'best_y_true':  [],'best_y_pred': [],\n",
        "              'best_f1':  [], 'train_f1': [], 'val_f1': [], 'train_features': [], 'val_features': [],\n",
        "              'test_features': [], 'best_epoch': []}\n",
        "\n",
        "    f_train_dataset = tio.SubjectsDataset(train_subjects)\n",
        "    f_train_dataloader = DataLoader(f_train_dataset, batch_size=batch_size, shuffle=False)\n",
        "    f_val_dataset = tio.SubjectsDataset(val_subjects)\n",
        "    f_val_dataloader = DataLoader(f_val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    f_test_dataset = tio.SubjectsDataset(test_subjects)\n",
        "    f_test_dataloader = DataLoader(f_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
        "        train_X, val_X = [X[i] for i in train_idx], [X[i] for i in val_idx]\n",
        "\n",
        "        # Count the class occurrences to determine weights\n",
        "        class_counts = {0: 0, 1: 0}\n",
        "        for x in train_X:\n",
        "            class_counts[x['label']] += 1  # Access the label correctly\n",
        "\n",
        "        # Calculate weights for each class based on occurrences\n",
        "        weights_per_class = {cls: 1.0 / count for cls, count in class_counts.items()}\n",
        "\n",
        "        # Assign a weight to each sample in the training set based on its class\n",
        "        sample_weights = [weights_per_class[x['label']] for x in train_X]  # Access the label correctly\n",
        "        sample_weights = torch.tensor(sample_weights, dtype=torch.float)\n",
        "\n",
        "        # Create a WeightedRandomSampler to handle class imbalance\n",
        "        sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = tio.SubjectsDataset(train_X,transform=augmentation_transforms)  # Applies augmentation conditionally\n",
        "        val_dataset = tio.SubjectsDataset(val_X)  # No augmentation for validation dataset\n",
        "\n",
        "        # Create dataloaders, utilizing the sampler for the training set to address class imbalance\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, shuffle=False)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        model = model_constructor().to(device).float()\n",
        "        model.apply(init_weights_he)\n",
        "\n",
        "        global model_name # for later ploting\n",
        "        model_name = model.__class__.__name__\n",
        "\n",
        "        # Hyperparameters configuration\n",
        "        num_train_samples = len(train_dataloader.dataset)  # Or compute it manually from your dataset\n",
        "        num_training_steps = num_train_samples // train_dataloader.batch_size * num_epochs  # Full passes through the dataset for 20 epochs\n",
        "        num_warmup_steps = round(num_training_steps * 0.1)  # Around 10% of the training data for warmup\n",
        "\n",
        "        # Instantiate the optimizer\n",
        "        optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Get the learning rate scheduler\n",
        "        total_steps = num_training_steps\n",
        "        warmup_percentage = num_warmup_steps / total_steps\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps)\n",
        "\n",
        "        # Loss Function\n",
        "        weights = torch.tensor([1.0, 1.0], dtype=torch.float32).to(device)\n",
        "        criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "\n",
        "        scaler = GradScaler()\n",
        "        best_val_loss = float('inf')\n",
        "        train_losses, val_losses = [], []\n",
        "        best_f1 = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            total_train_loss = 0.0\n",
        "            for subject in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs} - Training'):\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                mri = subject['mri'][tio.DATA].to(device)\n",
        "                dose = subject['dose'][tio.DATA].to(device)\n",
        "                struct = subject['struct'][tio.DATA].to(device)\n",
        "                labels = subject['label'].to(device)\n",
        "\n",
        "                with autocast():\n",
        "                    outputs = model(mri, dose, struct)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "            avg_train_loss = total_train_loss / len(train_dataloader.dataset)\n",
        "            train_losses.append(avg_train_loss)\n",
        "\n",
        "            model.eval()\n",
        "            total_val_loss = 0.0\n",
        "            y_pred, y_true = [], [] # it is important to place the initialization here, to we collect only the last ones in the fold\n",
        "            with torch.no_grad(), autocast():\n",
        "                for subject in tqdm(val_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs} - Validation'):\n",
        "                    mri = subject['mri'][tio.DATA].to(device)\n",
        "                    dose = subject['dose'][tio.DATA].to(device)\n",
        "                    struct = subject['struct'][tio.DATA].to(device)\n",
        "                    labels = subject['label'].to(device)\n",
        "\n",
        "                    outputs = model(mri, dose, struct)  # Again, no feature_extract=True here\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    total_val_loss += loss.item()\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    y_pred.extend(preds.cpu().numpy())\n",
        "                    y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "            avg_val_loss = total_val_loss / len(val_dataloader.dataset)\n",
        "            val_losses.append(avg_val_loss)\n",
        "\n",
        "            f1,precision,recall=f1_score(y_true, y_pred,zero_division=0.0),precision_score(y_true, y_pred,zero_division=0.0),recall_score(y_true, y_pred,zero_division=0.0)\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}: Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "            print(f\"Validation - F1/Precision/Recall: {f1:.4f}/{precision:.4f}/{recall:.4f}\")\n",
        "            print(f\"Validation - y_true: {y_true}\\nValidation - y_pred: {y_pred}\")\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_epoch = epoch\n",
        "                best_y_pred = y_pred\n",
        "                best_y_true = y_true\n",
        "                print(f\"New best F1 score: {best_f1:.4f}\")\n",
        "                fe = FeatureExtractor(model, device)\n",
        "                train_features,val_features,test_features = fe.extract_and_store_features(f_train_dataloader, f_val_dataloader, f_test_dataloader)\n",
        "                train_f1 = evaluate_model_on_dataloader(f_train_dataloader,model,device)\n",
        "                val_f1 = evaluate_model_on_dataloader(f_val_dataloader,model,device)\n",
        "            if avg_val_loss < best_val_loss:\n",
        "                best_val_loss = avg_val_loss\n",
        "                print(f\"New best val loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "        # Accumulate the stats for this iteration and fold\n",
        "        output['fold'].append(fold)\n",
        "        output['best_y_true'].append(best_y_true)\n",
        "        output['best_y_pred'].append(best_y_pred)\n",
        "        output['train_losses'].append(train_losses)\n",
        "        output['val_losses'].append(val_losses)\n",
        "        output['best_f1'].append(best_f1)\n",
        "        output['train_f1'].append(train_f1)\n",
        "        output['val_f1'].append(val_f1)\n",
        "        output['train_features'].append(train_features)\n",
        "        output['val_features'].append(val_features)\n",
        "        output['test_features'].append(test_features)\n",
        "        output['best_epoch'].append(best_epoch)\n",
        "\n",
        "        # Free up memory (if on GPU)\n",
        "        del model, optimizer, scheduler, train_dataloader, val_dataloader\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k6RpudV81RH",
        "outputId": "78a604ba-4c47-447e-9d4d-7b514732fda0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1/1\n",
            "Fold 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/q/.virtualenvs/r/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "Epoch 1/20 - Training:   0%|          | 0/34 [00:00<?, ?it/s]/home/q/.virtualenvs/r/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Epoch 1/20 - Training: 100%|██████████| 34/34 [00:37<00:00,  1.09s/it]\n",
            "Epoch 1/20 - Validation: 100%|██████████| 9/9 [00:02<00:00,  3.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: Training Loss: 0.2866, Validation Loss: 0.1628\n",
            "Validation - F1/Precision/Recall: 0.1667/0.1429/0.2000\n",
            "Validation - y_true: [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "Validation - y_pred: [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
            "New best F1 score: 0.1667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/q/.virtualenvs/r/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "/home/q/.virtualenvs/r/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best val loss: 0.1628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20 - Training:   0%|          | 0/34 [00:00<?, ?it/s]/home/q/.virtualenvs/r/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Epoch 2/20 - Training: 100%|██████████| 34/34 [00:38<00:00,  1.13s/it]\n",
            "Epoch 2/20 - Validation: 100%|██████████| 9/9 [00:02<00:00,  3.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: Training Loss: 1.7664, Validation Loss: 0.4114\n",
            "Validation - F1/Precision/Recall: 0.0000/0.0000/0.0000\n",
            "Validation - y_true: [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "Validation - y_pred: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20 - Training:   0%|          | 0/34 [00:00<?, ?it/s]/home/q/.virtualenvs/r/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Epoch 3/20 - Training: 100%|██████████| 34/34 [00:39<00:00,  1.15s/it]\n",
            "Epoch 3/20 - Validation: 100%|██████████| 9/9 [00:03<00:00,  2.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: Training Loss: 0.9382, Validation Loss: 0.1248\n",
            "Validation - F1/Precision/Recall: 0.0000/0.0000/0.0000\n",
            "Validation - y_true: [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "Validation - y_pred: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "New best val loss: 0.1248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20 - Training:   0%|          | 0/34 [00:00<?, ?it/s]/home/q/.virtualenvs/r/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Epoch 4/20 - Training: 100%|██████████| 34/34 [00:47<00:00,  1.39s/it]\n",
            "Epoch 4/20 - Validation: 100%|██████████| 9/9 [00:03<00:00,  2.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: Training Loss: 0.2332, Validation Loss: 0.3243\n",
            "Validation - F1/Precision/Recall: 0.2564/0.1471/1.0000\n",
            "Validation - y_true: [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "Validation - y_pred: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "New best F1 score: 0.2564\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()  \u001b[38;5;66;03m# Reset df_results if the model has changed\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     prev_model_constructor \u001b[38;5;241m=\u001b[39m model_constructor  \u001b[38;5;66;03m# Update the tracking variable\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mrun_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_subjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_constructor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m model_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(n_splits),\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m: [model_name]\u001b[38;5;241m*\u001b[39mn_splits,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m: [iterations]\u001b[38;5;241m*\u001b[39mn_splits,\n\u001b[1;32m     48\u001b[0m }\n\u001b[1;32m     50\u001b[0m df1\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(output)\n",
            "Cell \u001b[0;32mIn[11], line 143\u001b[0m, in \u001b[0;36mrun_cross_validation\u001b[0;34m(X, model_constructor, learning_rate, batch_size, iteration, n_splits, num_epochs, device)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew best F1 score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m fe \u001b[38;5;241m=\u001b[39m FeatureExtractor(model, device)\n\u001b[0;32m--> 143\u001b[0m train_features,val_features,test_features \u001b[38;5;241m=\u001b[39m \u001b[43mfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_and_store_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_train_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_val_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_test_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m train_f1 \u001b[38;5;241m=\u001b[39m evaluate_model_on_dataloader(f_train_dataloader,model,device)\n\u001b[1;32m    145\u001b[0m val_f1 \u001b[38;5;241m=\u001b[39m evaluate_model_on_dataloader(f_val_dataloader,model,device)\n",
            "Cell \u001b[0;32mIn[9], line 41\u001b[0m, in \u001b[0;36mFeatureExtractor.extract_and_store_features\u001b[0;34m(self, train_dataloader, val_dataloader, test_dataloader)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_and_store_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_dataloader, val_dataloader, test_dataloader):\n\u001b[0;32m---> 41\u001b[0m     train_features, train_labels, train_lesions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     val_features, val_labels, val_lesions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(val_dataloader)\n\u001b[1;32m     43\u001b[0m     test_features, test_labels, test_lesions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(test_dataloader)\n",
            "Cell \u001b[0;32mIn[9], line 27\u001b[0m, in \u001b[0;36mFeatureExtractor.extract_features\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     24\u001b[0m lesion \u001b[38;5;241m=\u001b[39m subject[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlesion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m output_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstruct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_extract\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Store features and labels\u001b[39;00m\n\u001b[1;32m     30\u001b[0m features\u001b[38;5;241m.\u001b[39mappend(output_features\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# Convert to numpy array\u001b[39;00m\n",
            "File \u001b[0;32m~/.virtualenvs/r/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.virtualenvs/r/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[5], line 187\u001b[0m, in \u001b[0;36mEarlyFusion3DCNN.forward\u001b[0;34m(self, x_mri, x_dose, x_struct, feature_extract)\u001b[0m\n\u001b[1;32m    185\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_mri, x_dose, x_struct), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    186\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))))\n\u001b[0;32m--> 187\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Optionally return extracted features before classification\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_extract:\n",
            "File \u001b[0;32m~/.virtualenvs/r/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.virtualenvs/r/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.virtualenvs/r/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/.virtualenvs/r/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.virtualenvs/r/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.virtualenvs/r/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "df_results=pd.DataFrame()\n",
        "\n",
        "# Cross-validation setup\n",
        "num_epochs = 20\n",
        "model_constructors = [EarlyFusion3DCNN, MidFusion3DCNN, LateFusion3DCNN]\n",
        "batch_sizes = [4, 8, 16, 32]\n",
        "learning_rates = [0.01, 0.001, 0.0001]\n",
        "n_splits = 5\n",
        "iterations = 1\n",
        "\n",
        "combination_generator = itertools.product(\n",
        "    model_constructors,\n",
        "    [learning_rate for learning_rate in learning_rates],\n",
        "    [batch_size for batch_size in batch_sizes],\n",
        "    range(iterations),\n",
        "    [n_splits],\n",
        ")\n",
        "\n",
        "prev_model_constructor = None  # Initialize tracking variable\n",
        "\n",
        "for config in combination_generator:\n",
        "    model_constructor, learning_rate, batch_size, iteration, n_splits = config\n",
        "    print(f\"Iteration {iteration+1}/{iterations}\")\n",
        "    model_name = model_constructor().__class__.__name__\n",
        "\n",
        "    if model_constructor != prev_model_constructor:\n",
        "        df_results = pd.DataFrame()  # Reset df_results if the model has changed\n",
        "        prev_model_constructor = model_constructor  # Update the tracking variable\n",
        "\n",
        "    output = run_cross_validation(train_subjects, model_constructor, learning_rate, batch_size, iteration, n_splits,num_epochs,device)\n",
        "\n",
        "    model_data = {\n",
        "        'fold': range(n_splits),\n",
        "        'model_name': [model_name]*n_splits,\n",
        "        'loss': ['FocalLoss']*n_splits,\n",
        "        'num_epochs': [num_epochs]*n_splits,\n",
        "        'n_splits': [n_splits]*n_splits,\n",
        "        'batch_size': [batch_size]*n_splits,\n",
        "        'learning_rate': [learning_rate]*n_splits,\n",
        "        'iteration': [iteration]*n_splits,\n",
        "        'iterations': [iterations]*n_splits,\n",
        "    }\n",
        "\n",
        "    df1=pd.DataFrame(output)\n",
        "    df2=pd.DataFrame(model_data)\n",
        "    df_results = pd.concat([df_results, df1.merge(df2, on='fold')], ignore_index=True)\n",
        "\n",
        "\n",
        "    # Generate a timestamp\n",
        "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "    # Specify the file path\n",
        "    file_path = f\"{base_folder}/pickle/FeatureExtraction_FocalLoss_{model_name}_{learning_rate}_{batch_size}_{timestamp}.pkl\"\n",
        "\n",
        "    # Saving the dictionary using pickle\n",
        "    with open(file_path, 'ab') as file:\n",
        "        pickle.dump(df_results, file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4dWohPd7hqV"
      },
      "outputs": [],
      "source": [
        "# df_results.to_csv(f\"{base_folder}/Last_Two_models_Focal_FeatureExtractionMRI_validation_results.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
